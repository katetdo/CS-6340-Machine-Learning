Good job working through this problem. The main goal here was to give you practice with managing the freedom associated with building these deep learning models on non tabular data. It looks to me as though you ran into some issues with mode collapse in which the model simply predicts the modal category (normal) for all observations. This is a known way that deep learning models fail. One thing to think about with these results -- accuracy isn't necessarily the best metric here b/c of the class imbalance; we used it because it is easy. In reality, some mistakes are worse than others. Calling an Afib sequence as normal is probably worse than other mistakes, so every time you classify an Afib sequence as anything other than normal you're improving patient outcomes. Also, note that you should expect around 25% accuracy from a totally random model, so 50% accuracy is a 100% increase!