Well done! Nice discussion of the contribution that the different decision boundaries make to the solution of the overall classification problem. One thing that I notice in your code that I'll comment on: for both the MLP model and the logit you've got a single model definition statement, e.g. mlp = MLPClassifier(hidden_layer_sizes = 4, max_iter = 1000, solver = 'lbfgs'). And you've fit this model a couple times without removing/redefining it. Python sometimes handles things like this in an odd fashion, where if you sequentially train the same model object the second + trainings do not overwrite the original training but rather add to it in unpredictable way. I often prefer to define multiple model objects (e.g. mlp_petal = ... AND mlp_sepal = ...) to avoid any ambiguity.